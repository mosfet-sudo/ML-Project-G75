# -*- coding: utf-8 -*-
"""nasa_xinyu_knn_nb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zhLK6a9-DJd67QIvNnP64dMqKNoGPccR

#### cell 0：NASA C-MAPSS Data Loading + Feature Extraction Pipeline
"""

import os
import requests
import pandas as pd
from pathlib import Path
from io import StringIO

#Kaggle fallback downloader (if GitHub goes down)
try:
    import kagglehub
    KAGGLE_PATH = kagglehub.dataset_download("behrad3d/nasa-cmaps")
except ImportError:
    print("Kagglehub is not installed, please manually pip install kagglehub")

# Data root directory structure
RAW_DIR = Path("raw_data_nasa")
FEAT_DIR = Path("features_nasa")
RAW_DIR.mkdir(exist_ok=True)
FEAT_DIR.mkdir(exist_ok=True)

# Common column name definitions
column_names = ['unit', 'cycle'] + [f'op_set{i}' for i in range(1, 4)] + [f'sensor{i}' for i in range(1, 22)]

def read_nasa_file(filename):
    """
    Try reading NASA data files from GitHub, Kaggle, and locally in sequence and caching them as .txt files.
    """
    url_github = f"https://raw.githubusercontent.com/LahiruJayasinghe/RUL-Net/master/CMAPSSData/{filename}"
    local_fallback = RAW_DIR / filename

    # Step 1: Try reading from GitHub
    try:
        print(f" Trying GitHub: {filename}")
        r = requests.get(url_github, timeout=10)
        r.raise_for_status()
        with open(local_fallback, "w") as f:
            f.write(r.text)
        print(f" Cached {filename} from GitHub")
        return pd.read_csv(StringIO(r.text), sep=r'\s+', header=None, names=column_names)
    except Exception as e:
        print(f" GitHub failed: {e}")

    # Step 2: Try reading from the kagglehub path
    try:
        print(f" Trying Kaggle: {filename}")
        kaggle_file = os.path.join(KAGGLE_PATH, "CMAPSSData", filename)
        with open(kaggle_file, "r") as f_in, open(local_fallback, "w") as f_out:
            content = f_in.read()
            f_out.write(content)
        print(f" Cached {filename} from Kaggle")
        return pd.read_csv(kaggle_file, sep=r'\s+', header=None, names=column_names)
    except Exception as e:
        print(f" Kaggle failed: {e}")

    # Step 3: Finally, fallback to the cached local
    if local_fallback.exists():
        print(f" Loading cached local file: {filename}")
        return pd.read_csv(local_fallback, sep=r'\s+', header=None, names=column_names)

    raise FileNotFoundError(f" Cannot load {filename} from any source")

def generate_features(set_id):
    print(f"\n Processing {set_id}")
    train = read_nasa_file(f"train_{set_id}.txt")
    test = read_nasa_file(f"test_{set_id}.txt")
    rul = read_nasa_file(f"RUL_{set_id}.txt")

    # If rul is a one-dimensional vector (not a DataFrame), force it to be a column
    if isinstance(rul, pd.DataFrame):
        test_y = rul
    else:
        test_y = pd.DataFrame(rul)

    # Extract X/y features
    train_X = train.drop(['unit', 'cycle'], axis=1)
    train_y = train['cycle']
    test_X = test.drop(['unit', 'cycle'], axis=1)

    #save as csv
    train_X.to_csv(FEAT_DIR / f"X_train_{set_id}.csv", index=False)
    train_y.to_csv(FEAT_DIR / f"y_train_{set_id}.csv", index=False)
    test_X.to_csv(FEAT_DIR / f"X_test_{set_id}.csv", index=False)
    test_y.to_csv(FEAT_DIR / f"y_test_{set_id}.csv", index=False)

    print(f" Features saved for {set_id} to {FEAT_DIR}/")


# Main process: Process FD001 ~ FD004
for fd in ['FD001', 'FD002', 'FD003', 'FD004']:
    try:
        generate_features(fd)
    except Exception as e:
        print(f"× Error for {fd}: {e}")

"""####Cell 1: Load the processed feature files CSVs"""

import os
import pandas as pd

#Data Path
FEATURES_DIR = "features_nasa"

# All subsets
fds = ["FD001", "FD002", "FD003", "FD004"]

# Unified management with dictionary
data = {}

for fd in fds:
    data[fd] = {
        "X_train": pd.read_csv(os.path.join(FEATURES_DIR, f"X_train_{fd}.csv")),
        "y_train": pd.read_csv(os.path.join(FEATURES_DIR, f"y_train_{fd}.csv")),
        "X_test": pd.read_csv(os.path.join(FEATURES_DIR, f"X_test_{fd}.csv")),
        "y_test": pd.read_csv(os.path.join(FEATURES_DIR, f"y_test_{fd}.csv")),
    }

print(" All features loaded successfully.")

for fd in fds:
    print(fd, data[fd]["X_train"].shape, data[fd]["y_train"].shape,
          data[fd]["X_test"].shape, data[fd]["y_test"].shape)

"""#### Cell 2: Feature/label splitting + possible preprocessing (e.g. normalization)

"""

from sklearn.preprocessing import StandardScaler

scalers = {}
for fd in fds:
    X_tr = data[fd]["X_train"]
    X_te = data[fd]["X_test"]
    scaler = StandardScaler()
    scaler.fit(X_tr)
    X_tr_scaled = pd.DataFrame(scaler.transform(X_tr), columns=X_tr.columns)
    X_te_scaled = pd.DataFrame(scaler.transform(X_te), columns=X_te.columns)
    # alternate data
    data[fd]["X_train_scaled"] = X_tr_scaled
    data[fd]["X_test_scaled"] = X_te_scaled
    scalers[fd] = scaler

print("Features standardized (zero mean, unit var) per FD subset.")

"""####Cell 3: Split into validation set (draw a holdout from the training set or do cross-validation setup)

"""

from sklearn.model_selection import train_test_split

for fd in fds:
    X = data[fd]["X_train_scaled"]
    y = data[fd]["y_train"]
    X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
    data[fd].update({
        "X_tr": X_tr, "X_val": X_val,
        "y_tr": y_tr, "y_val": y_val
    })
    print(f"{fd} split: train {X_tr.shape}, val {X_val.shape}")

"""#### Cell 4: Training a model using KNN regression + hyperparameter search"""

from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import GridSearchCV

knn_models = {}

for fd in fds:
    X_tr = data[fd]["X_tr"]
    y_tr = data[fd]["y_tr"]
    knn = KNeighborsRegressor()
    param_grid = {
        "n_neighbors": [3, 5, 7, 9],
        "weights": ["uniform", "distance"],
        "p": [1, 2]  # p=1 → Manhattan distance, p=2 → Euclidean distance
    }
    grid = GridSearchCV(knn, param_grid, cv=3, scoring="neg_mean_squared_error", n_jobs=-1)
    grid.fit(X_tr, y_tr)
    best = grid.best_estimator_
    knn_models[fd] = best
    print(f"KNN best for {fd}: {grid.best_params_}")

"""#### Cell 5: Evaluate on validation and test sets + save predictions"""

from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import os

results = []

for fd in fds:
    model = knn_models[fd]
    X_val = data[fd]["X_val"]
    y_val = data[fd]["y_val"]
    X_te = data[fd]["X_test_scaled"]
    y_te = data[fd]["y_test"]

    print(f"{fd} shapes — X_val: {X_val.shape}, y_val: {y_val.shape}, X_te: {X_te.shape}, y_te: {getattr(y_te, 'shape', None)}")

    # If y_te is a DataFrame with more than 1 column
    if isinstance(y_te, pd.DataFrame):
        if y_te.shape[1] > 1:
            print(f"  {fd} y_te has {y_te.shape[1]} columns, keeping only first column")
            y_te = y_te.iloc[:, 0]  # turn to Series
        elif y_te.shape[1] == 1:
            y_te = y_te.iloc[:, 0]
    # If it is still two-dimensional numpy
    if isinstance(y_te, np.ndarray) and y_te.ndim > 1:
        print(f"  {fd} y_te is numpy with ndim {y_te.ndim}, flattening")
        y_te = y_te.flatten()

    #Now y_te should be a 1D array / Series

    #Alignment Length
    if X_te.shape[0] != len(y_te):
        min_n = min(X_te.shape[0], len(y_te))
        print(f"  Mismatch: X_te {X_te.shape[0]} vs y_te {len(y_te)}, truncating to {min_n}")
        X_te = X_te.iloc[:min_n].reset_index(drop=True)
        if hasattr(y_te, "iloc"):
            y_te = y_te.iloc[:min_n].reset_index(drop=True)
        else:
            y_te = y_te[:min_n]

    # predict
    y_val_pred = model.predict(X_val)
    y_te_pred = model.predict(X_te)

    mae_val = mean_absolute_error(y_val, y_val_pred)
    rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))
    mae_te = mean_absolute_error(y_te, y_te_pred)
    rmse_te = np.sqrt(mean_squared_error(y_te, y_te_pred))

    results.append({
        "FD": fd,
        "MAE_val": mae_val, "RMSE_val": rmse_val,
        "MAE_test": mae_te, "RMSE_test": rmse_te
    })

    # Save the predictions and true values, making sure they are both one-dimensional
    df_save = pd.DataFrame({
        "truth": np.array(y_te).reshape(-1),
        "pred": np.array(y_te_pred).reshape(-1)
    })
    df_save.to_csv(os.path.join(FEATURES_DIR, f"pred_{fd}.csv"), index=False)

results_df = pd.DataFrame(results)
print("=== Evaluation Summary ===")
print(results_df)

"""#### KNN result visualization"""

import matplotlib.pyplot as plt

for fd in fds:
    df_pred = pd.read_csv(os.path.join(FEATURES_DIR, f"pred_{fd}.csv"))
    plt.figure(figsize=(8,4))
    plt.plot(df_pred["truth"].values, label="True RUL")
    plt.plot(df_pred["pred"].values, label="Predicted RUL", linestyle='--')
    plt.title(f"{fd} RUL: True Value vs Prediction")
    plt.xlabel("Sample Index")
    plt.ylabel("Remaining useful life (RUL)")
    plt.legend()
    plt.tight_layout()
    plt.show()
    print()

"""#### Naive Bayes，GaussianNB"""

#  trained using GaussianNB
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV

nb_models = {}

for fd in fds:
    X_tr = data[fd]["X_tr"]
    y_tr = data[fd]["y_tr"]
    # GaussianNB itself has no hyperparameters that can be tuned (except var_smoothing)
    nb = GaussianNB()
    param_grid = {
        "var_smoothing": [1e-9, 1e-8, 1e-7]
    }
    grid = GridSearchCV(nb, param_grid, cv=3, scoring="neg_mean_squared_error", n_jobs=-1)
    grid.fit(X_tr, y_tr)
    best = grid.best_estimator_
    nb_models[fd] = best
    print(f"NB best for {fd}: {grid.best_params_}")

"""#### Cell 5 (NB version): Evaluate + Save Predictions"""

#Cell 5 (NB version): Evaluate + Save Predictions
from sklearn.metrics import mean_absolute_error, mean_squared_error
import numpy as np
import os

results_nb = []

for fd in fds:
    model = nb_models[fd]
    X_val = data[fd]["X_val"]
    y_val = data[fd]["y_val"]
    X_te = data[fd]["X_test_scaled"]
    y_te = data[fd]["y_test"]

    # Dealing with possible multi-column y_te problems is similar to the previous section
    if isinstance(y_te, pd.DataFrame):
        if y_te.shape[1] > 1:
            y_te = y_te.iloc[:, 0]
        else:
            y_te = y_te.iloc[:, 0]

    # Alignment Lines
    if X_te.shape[0] != len(y_te):
        min_n = min(X_te.shape[0], len(y_te))
        X_te = X_te.iloc[:min_n].reset_index(drop=True)
        y_te = y_te.iloc[:min_n].reset_index(drop=True)

    y_val_pred = model.predict(X_val)
    y_te_pred = model.predict(X_te)

    mae_val = mean_absolute_error(y_val, y_val_pred)
    rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))
    mae_te = mean_absolute_error(y_te, y_te_pred)
    rmse_te = np.sqrt(mean_squared_error(y_te, y_te_pred))

    results_nb.append({
        "FD": fd,
        "MAE_val": mae_val, "RMSE_val": rmse_val,
        "MAE_test": mae_te, "RMSE_test": rmse_te
    })

    pd.DataFrame({"truth": y_te.values, "pred": y_te_pred}).to_csv(
        os.path.join(FEAT_DIR, f"pred_nb_{fd}.csv"), index=False
    )

results_nb_df = pd.DataFrame(results_nb)
print("=== NB Evaluation Summary ===")
print(results_nb_df)

"""#### Cell 6 (Visual NB version)"""

#Cell 6 (Visual NB version)
import matplotlib.pyplot as plt

for fd in fds:
    df_nb = pd.read_csv(os.path.join(FEAT_DIR, f"pred_nb_{fd}.csv"))
    plt.figure(figsize=(8,4))
    plt.plot(df_nb["truth"].values, label="True RUL")
    plt.plot(df_nb["pred"].values, label="NB Predicted RUL", linestyle='--')
    plt.title(f"{fd} RUL: True Value vs NB Prediction")
    plt.xlabel("Sample Index")
    plt.ylabel("RUL")
    plt.legend()
    plt.tight_layout()
    plt.show()

# summary results
results_nb_df.to_csv(os.path.join(FEAT_DIR, "evaluation_summary_nb.csv"), index=False)
print("Saved NB evaluation summary to evaluation_summary_nb.csv")